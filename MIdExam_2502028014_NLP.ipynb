{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51241488",
   "metadata": {},
   "source": [
    "3. Pos Tagging \n",
    "\n",
    "    A) Annotate the sentences below with the correct series of tags with Penn \n",
    "    Treebank Tagset. You may use any programming language and libraries of your \n",
    "    choice. Then, explain the process.\n",
    "\n",
    "    - Jackson is going to book that ticket on Sunday morning.\n",
    "    - Jackson returns the book he borrowed from the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5d410ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bfbfe2",
   "metadata": {},
   "source": [
    "Natural Language Toolkit (NLTK) library is one of several libraries and tools to perform POS tagging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "272abf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt') #using the punkt tokenizer\n",
    "nltk.download('averaged_perceptron_tagger') #tagging words with their parts of speech (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5dae814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d01bf5",
   "metadata": {},
   "source": [
    "word_tokenize is a function that relies on the 'punkt' model to split a sentence into individual words or tokens. So, we can move on to the next step which is tagging each word with its Part of Speech (POS) from the Penn Treebank Tagset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab82af1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokenization of S1:  ['Jackson', 'is', 'going', 'to', 'book', 'that', 'ticket', 'on', 'Sunday', 'morning', '.']\n",
      "\n",
      "\n",
      "Word Tokenization of S2:  ['Jackson', 'returns', 'the', 'book', 'he', 'borrowed', 'from', 'the', 'library', '.']\n"
     ]
    }
   ],
   "source": [
    "S1 = \"Jackson is going to book that ticket on Sunday morning.\"\n",
    "S2 = \"Jackson returns the book he borrowed from the library.\"\n",
    "\n",
    "T1 = word_tokenize(S1)\n",
    "T2 = word_tokenize(S2)\n",
    "print(\"Word Tokenization of S1: \",T1)\n",
    "print(\"\\n\\nWord Tokenization of S2: \",T2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5657af7",
   "metadata": {},
   "source": [
    "From the output above we can see a list of words from S1 and S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5976df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a311ef",
   "metadata": {},
   "source": [
    "pos_tag is a function that relies on the 'averaged_perceptron_tagger' model to perform POS tagging by using the Penn Treebank Tagset as default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0c73a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tags of S1 [('Jackson', 'NNP'), ('is', 'VBZ'), ('going', 'VBG'), ('to', 'TO'), ('book', 'NN'), ('that', 'WDT'), ('ticket', 'NN'), ('on', 'IN'), ('Sunday', 'NNP'), ('morning', 'NN'), ('.', '.')]\n",
      "\n",
      "\n",
      "POS tags of S2 [('Jackson', 'NNP'), ('returns', 'VBZ'), ('the', 'DT'), ('book', 'NN'), ('he', 'PRP'), ('borrowed', 'VBD'), ('from', 'IN'), ('the', 'DT'), ('library', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "P1 = pos_tag(T1)\n",
    "P2 = pos_tag(T2)\n",
    "\n",
    "print(\"POS tags of S1\", P1)\n",
    "print(\"\\n\\nPOS tags of S2\", P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea004ea5",
   "metadata": {},
   "source": [
    "From the output above we can see the expected value of correct series of tags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
